{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data as data\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP,LeNet\n",
    "========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP,self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28*3,8192)\n",
    "        self.BN1 = nn.BatchNorm1d(8192)\n",
    "        self.fc2 = nn.Linear(8192,8192)\n",
    "        self.BN2 = nn.BatchNorm1d(8192)\n",
    "        self.fc3 = nn.Linear(8192,4096)\n",
    "        self.BN3 = nn.BatchNorm1d(4096)\n",
    "        self.fc4 = nn.Linear(4096,2048)\n",
    "        self.BN4 = nn.BatchNorm1d(2048)\n",
    "        self.fc5 = nn.Linear(2048,18)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = x.view(-1,28*28*3)\n",
    "#         out = F.sigmoid(self.fc1(out))\n",
    "#         out = F.sigmoid(self.fc2(out))\n",
    "#         out = F.sigmoid(self.fc3(out))\n",
    "#         out = F.sigmoid(self.fc4(out))\n",
    "\n",
    "        out = F.sigmoid(self.BN1(self.fc1(out)))\n",
    "        out = F.sigmoid(self.BN2(self.fc2(out)))\n",
    "        out = F.sigmoid(self.BN3(self.fc3(out)))\n",
    "        out = F.sigmoid(self.BN4(self.fc4(out)))\n",
    "        out = F.sigmoid(self.fc5(out))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1   = nn.Linear(16*5*5, 120)\n",
    "        self.fc2   = nn.Linear(120, 84)\n",
    "        self.fc3   = nn.Linear(84, 18)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.conv1(x))\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = F.relu(self.conv2(out))\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = out.view(out.size(0),-1)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = F.relu(self.fc2(out))\n",
    "        out = self.fc3(out)\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 2.880234718\n",
      "Epoch [11/100], Loss: 2.871831417\n",
      "Epoch [21/100], Loss: 2.930654526\n",
      "Epoch [31/100], Loss: 2.955864668\n",
      "Epoch [41/100], Loss: 2.804604292\n",
      "Epoch [51/100], Loss: 2.880234718\n",
      "Epoch [61/100], Loss: 2.930654526\n",
      "Epoch [71/100], Loss: 2.813007832\n",
      "Epoch [81/100], Loss: 2.787797689\n",
      "Epoch [91/100], Loss: 2.863427877\n",
      "Accuracy of the network on the test images: 6.350000 %\n",
      "mlp_Acc6.35_epoch100_lr0.1.pkl\n",
      "Epoch [1/100], Loss: 6.978487968\n",
      "Epoch [11/100], Loss: 2.748284578\n",
      "Epoch [21/100], Loss: 2.816827536\n",
      "Epoch [31/100], Loss: 2.851258278\n",
      "Epoch [41/100], Loss: 2.776464939\n",
      "Epoch [51/100], Loss: 2.821700573\n",
      "Epoch [61/100], Loss: 2.846170425\n",
      "Epoch [71/100], Loss: 2.763332367\n",
      "Epoch [81/100], Loss: 2.881966352\n",
      "Epoch [91/100], Loss: 2.793083668\n",
      "Accuracy of the network on the test images: 10.770000 %\n",
      "lenet_Acc10.77_epoch100_lr0.1.pkl\n",
      "Epoch [1/150], Loss: 2.847507954\n",
      "Epoch [11/150], Loss: 2.847507954\n",
      "Epoch [21/150], Loss: 2.813894510\n",
      "Epoch [31/150], Loss: 2.906331539\n",
      "Epoch [41/150], Loss: 2.805491209\n",
      "Epoch [51/150], Loss: 2.939944983\n",
      "Epoch [61/150], Loss: 2.939944983\n",
      "Epoch [71/150], Loss: 2.839104652\n",
      "Epoch [81/150], Loss: 2.813894510\n",
      "Epoch [91/150], Loss: 2.855911493\n",
      "Epoch [101/150], Loss: 2.763474464\n",
      "Epoch [111/150], Loss: 2.855911493\n",
      "0.02\n",
      "Epoch [121/150], Loss: 2.746667624\n",
      "Epoch [131/150], Loss: 2.847507954\n",
      "0.004\n",
      "Epoch [141/150], Loss: 2.813894510\n",
      "Accuracy of the network on the test images: 6.350000 %\n",
      "mlp_Acc6.35_epoch150_lr0.1.pkl\n",
      "Epoch [1/150], Loss: 2.787711859\n",
      "Epoch [11/150], Loss: 2.805627823\n",
      "Epoch [21/150], Loss: 2.814653873\n",
      "Epoch [31/150], Loss: 2.902003527\n",
      "Epoch [41/150], Loss: 2.776646137\n",
      "Epoch [51/150], Loss: 2.829033613\n",
      "Epoch [61/150], Loss: 2.806788683\n",
      "Epoch [71/150], Loss: 2.793087721\n",
      "Epoch [81/150], Loss: 2.743311167\n",
      "Epoch [91/150], Loss: 2.852942705\n",
      "Epoch [101/150], Loss: 2.841679096\n",
      "Epoch [111/150], Loss: 2.816230059\n",
      "0.02\n",
      "Epoch [121/150], Loss: 2.851113558\n",
      "Epoch [131/150], Loss: 2.735661268\n",
      "0.004\n",
      "Epoch [141/150], Loss: 2.803611517\n",
      "Accuracy of the network on the test images: 10.770000 %\n",
      "lenet_Acc10.77_epoch150_lr0.1.pkl\n",
      "Epoch [1/200], Loss: 2.877942801\n",
      "Epoch [11/200], Loss: 2.810715914\n",
      "Epoch [21/200], Loss: 2.869539499\n",
      "Epoch [31/200], Loss: 2.810715914\n",
      "Epoch [41/200], Loss: 2.802312613\n",
      "Epoch [51/200], Loss: 2.886346102\n",
      "Epoch [61/200], Loss: 2.869539261\n",
      "Epoch [71/200], Loss: 2.928362608\n",
      "Epoch [81/200], Loss: 2.793909073\n",
      "Epoch [91/200], Loss: 2.835926056\n",
      "Epoch [101/200], Loss: 2.810715914\n",
      "Epoch [111/200], Loss: 2.852732658\n",
      "0.02\n",
      "Epoch [121/200], Loss: 2.919959307\n",
      "Epoch [131/200], Loss: 2.894749165\n",
      "0.004\n",
      "Epoch [141/200], Loss: 2.886346102\n",
      "Epoch [151/200], Loss: 2.810715914\n",
      "0.0008\n",
      "Epoch [161/200], Loss: 2.751892328\n",
      "Epoch [171/200], Loss: 2.886346102\n",
      "0.00016\n",
      "Epoch [181/200], Loss: 2.886346102\n",
      "Epoch [191/200], Loss: 2.903152704\n",
      "Accuracy of the network on the test images: 8.080000 %\n",
      "mlp_Acc8.08_epoch200_lr0.1.pkl\n",
      "Epoch [1/200], Loss: 2.803351879\n",
      "Epoch [11/200], Loss: 2.769769430\n",
      "Epoch [21/200], Loss: 2.804757595\n",
      "Epoch [31/200], Loss: 2.801166296\n",
      "Epoch [41/200], Loss: 2.822589636\n",
      "Epoch [51/200], Loss: 2.788709641\n",
      "Epoch [61/200], Loss: 2.872775793\n",
      "Epoch [71/200], Loss: 2.774729013\n",
      "Epoch [81/200], Loss: 2.833534479\n",
      "Epoch [91/200], Loss: 2.807336330\n",
      "Epoch [101/200], Loss: 2.813635826\n",
      "Epoch [111/200], Loss: 2.848722458\n",
      "0.02\n",
      "Epoch [121/200], Loss: 2.840044498\n",
      "Epoch [131/200], Loss: 2.860649109\n",
      "0.004\n",
      "Epoch [141/200], Loss: 2.824351549\n",
      "Epoch [151/200], Loss: 2.789629698\n",
      "0.0008\n",
      "Epoch [161/200], Loss: 2.806303501\n",
      "Epoch [171/200], Loss: 2.781014919\n",
      "0.00016\n",
      "Epoch [181/200], Loss: 2.810245752\n",
      "Epoch [191/200], Loss: 2.777884722\n",
      "Accuracy of the network on the test images: 10.770000 %\n",
      "lenet_Acc10.77_epoch200_lr0.1.pkl\n",
      "Epoch [1/250], Loss: 2.922251463\n",
      "Epoch [11/250], Loss: 2.855024576\n",
      "Epoch [21/250], Loss: 2.846621275\n",
      "Epoch [31/250], Loss: 2.930654764\n",
      "Epoch [41/250], Loss: 2.871831417\n",
      "Epoch [51/250], Loss: 2.880234718\n",
      "Epoch [61/250], Loss: 2.813007832\n",
      "Epoch [71/250], Loss: 2.880234718\n",
      "Epoch [81/250], Loss: 2.829814434\n",
      "Epoch [91/250], Loss: 2.871831417\n",
      "Epoch [101/250], Loss: 2.821411133\n",
      "Epoch [111/250], Loss: 2.838217974\n",
      "0.02\n",
      "Epoch [121/250], Loss: 2.905444384\n",
      "Epoch [131/250], Loss: 2.871831417\n",
      "0.004\n",
      "Epoch [141/250], Loss: 2.821411133\n",
      "Epoch [151/250], Loss: 2.855024576\n",
      "0.0008\n",
      "Epoch [161/250], Loss: 2.871831417\n",
      "Epoch [171/250], Loss: 2.855024576\n",
      "0.00016\n",
      "Epoch [181/250], Loss: 2.871831417\n",
      "Epoch [191/250], Loss: 2.821411133\n",
      "3.2e-05\n",
      "Epoch [201/250], Loss: 2.829814434\n",
      "Epoch [211/250], Loss: 2.880234718\n",
      "6.4e-06\n",
      "Epoch [221/250], Loss: 2.829814434\n",
      "Epoch [231/250], Loss: 2.829814434\n",
      "1.28e-06\n",
      "Epoch [241/250], Loss: 2.813007832\n",
      "Accuracy of the network on the test images: 6.350000 %\n",
      "mlp_Acc6.35_epoch250_lr0.1.pkl\n",
      "Epoch [1/250], Loss: 2.892498016\n",
      "Epoch [11/250], Loss: 2.821208239\n",
      "Epoch [21/250], Loss: 2.851580143\n",
      "Epoch [31/250], Loss: 2.765240669\n",
      "Epoch [41/250], Loss: 2.834514141\n",
      "Epoch [51/250], Loss: 2.804564714\n",
      "Epoch [61/250], Loss: 2.816220522\n",
      "Epoch [71/250], Loss: 2.813017845\n",
      "Epoch [81/250], Loss: 2.834495306\n",
      "Epoch [91/250], Loss: 2.820164680\n",
      "Epoch [101/250], Loss: 2.861640930\n",
      "Epoch [111/250], Loss: 2.774475098\n",
      "0.02\n",
      "Epoch [121/250], Loss: 2.772134542\n",
      "Epoch [131/250], Loss: 2.787468910\n",
      "0.004\n",
      "Epoch [141/250], Loss: 2.779289246\n",
      "Epoch [151/250], Loss: 2.832741261\n",
      "0.0008\n",
      "Epoch [161/250], Loss: 2.853522062\n",
      "Epoch [171/250], Loss: 2.761283398\n",
      "0.00016\n",
      "Epoch [181/250], Loss: 2.826469898\n",
      "Epoch [191/250], Loss: 2.774531603\n",
      "3.2e-05\n",
      "Epoch [201/250], Loss: 2.759882927\n",
      "Epoch [211/250], Loss: 2.820369959\n",
      "6.4e-06\n",
      "Epoch [221/250], Loss: 2.788160801\n",
      "Epoch [231/250], Loss: 2.818718910\n",
      "1.28e-06\n",
      "Epoch [241/250], Loss: 2.817934752\n",
      "Accuracy of the network on the test images: 10.770000 %\n",
      "lenet_Acc10.77_epoch250_lr0.1.pkl\n",
      "Epoch [1/100], Loss: 2.737028599\n",
      "Epoch [11/100], Loss: 2.888288975\n",
      "Epoch [21/100], Loss: 2.938709021\n",
      "Epoch [31/100], Loss: 2.837868929\n",
      "Epoch [41/100], Loss: 2.947112322\n",
      "Epoch [51/100], Loss: 2.963918924\n",
      "Epoch [61/100], Loss: 2.846272230\n",
      "Epoch [71/100], Loss: 2.896692276\n",
      "Epoch [81/100], Loss: 2.854675531\n",
      "Epoch [91/100], Loss: 2.837868929\n",
      "Accuracy of the network on the test images: 6.350000 %\n",
      "mlp_Acc6.35_epoch100_lr0.05.pkl\n",
      "Epoch [1/100], Loss: 2.880431414\n",
      "Epoch [11/100], Loss: 2.104026318\n",
      "Epoch [21/100], Loss: 1.837316632\n",
      "Epoch [31/100], Loss: 1.850615501\n",
      "Epoch [41/100], Loss: 1.772388458\n",
      "Epoch [51/100], Loss: 1.739029527\n",
      "Epoch [61/100], Loss: 1.557233334\n",
      "Epoch [71/100], Loss: 1.809722543\n",
      "Epoch [81/100], Loss: 1.719546080\n",
      "Epoch [91/100], Loss: 1.746729851\n",
      "Accuracy of the network on the test images: 27.310000 %\n",
      "lenet_Acc27.31_epoch100_lr0.05.pkl\n",
      "Epoch [1/150], Loss: 2.855911493\n",
      "Epoch [11/150], Loss: 2.897928238\n",
      "Epoch [21/150], Loss: 2.830701351\n",
      "Epoch [31/150], Loss: 2.906331539\n",
      "Epoch [41/150], Loss: 2.813894510\n",
      "Epoch [51/150], Loss: 2.897928238\n",
      "Epoch [61/150], Loss: 2.855911493\n",
      "Epoch [71/150], Loss: 2.855911493\n",
      "Epoch [81/150], Loss: 2.855911493\n",
      "Epoch [91/150], Loss: 2.822298050\n",
      "Epoch [101/150], Loss: 2.864314795\n",
      "Epoch [111/150], Loss: 2.881121397\n",
      "0.01\n",
      "Epoch [121/150], Loss: 2.788684607\n",
      "Epoch [131/150], Loss: 2.923138380\n",
      "0.002\n",
      "Epoch [141/150], Loss: 2.855911493\n",
      "Accuracy of the network on the test images: 8.080000 %\n",
      "mlp_Acc8.08_epoch150_lr0.05.pkl\n",
      "Epoch [1/150], Loss: 2.730115891\n",
      "Epoch [11/150], Loss: 1.828168750\n",
      "Epoch [21/150], Loss: 1.850848198\n",
      "Epoch [31/150], Loss: 1.763653755\n",
      "Epoch [41/150], Loss: 1.557078719\n",
      "Epoch [51/150], Loss: 1.591459990\n",
      "Epoch [61/150], Loss: 1.721982718\n",
      "Epoch [71/150], Loss: 1.477421522\n",
      "Epoch [81/150], Loss: 1.552911639\n",
      "Epoch [91/150], Loss: 2.206851006\n",
      "Epoch [101/150], Loss: 1.766003728\n",
      "Epoch [111/150], Loss: 1.502095461\n",
      "0.01\n",
      "Epoch [121/150], Loss: 1.573403120\n",
      "Epoch [131/150], Loss: 1.754033089\n",
      "0.002\n",
      "Epoch [141/150], Loss: 1.595791101\n",
      "Accuracy of the network on the test images: 25.770000 %\n",
      "lenet_Acc25.77_epoch150_lr0.05.pkl\n",
      "Epoch [1/200], Loss: 2.855024576\n",
      "Epoch [11/200], Loss: 2.880234718\n",
      "Epoch [21/200], Loss: 2.913848162\n",
      "Epoch [31/200], Loss: 2.922251463\n",
      "Epoch [41/200], Loss: 2.855024576\n",
      "Epoch [51/200], Loss: 2.964267969\n",
      "Epoch [61/200], Loss: 2.905444860\n",
      "Epoch [71/200], Loss: 2.871831417\n",
      "Epoch [81/200], Loss: 2.754184246\n",
      "Epoch [91/200], Loss: 2.813007832\n",
      "Epoch [101/200], Loss: 2.829814434\n",
      "Epoch [111/200], Loss: 2.838217974\n",
      "0.01\n",
      "Epoch [121/200], Loss: 2.863427877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [131/200], Loss: 2.897041321\n",
      "0.002\n",
      "Epoch [141/200], Loss: 2.855024576\n",
      "Epoch [151/200], Loss: 2.863427877\n",
      "0.0004\n",
      "Epoch [161/200], Loss: 2.880234718\n",
      "Epoch [171/200], Loss: 2.855024576\n",
      "8e-05\n",
      "Epoch [181/200], Loss: 2.855024576\n",
      "Epoch [191/200], Loss: 2.813007832\n",
      "Accuracy of the network on the test images: 8.080000 %\n",
      "mlp_Acc8.08_epoch200_lr0.05.pkl\n",
      "Epoch [1/200], Loss: 2.767172337\n",
      "Epoch [11/200], Loss: 1.791464329\n",
      "Epoch [21/200], Loss: 1.957343102\n",
      "Epoch [31/200], Loss: 1.539062977\n",
      "Epoch [41/200], Loss: 1.613857269\n",
      "Epoch [51/200], Loss: 1.356849790\n",
      "Epoch [61/200], Loss: 1.563727617\n",
      "Epoch [71/200], Loss: 1.177800655\n",
      "Epoch [81/200], Loss: 2.429996967\n",
      "Epoch [91/200], Loss: 2.125413418\n",
      "Epoch [101/200], Loss: 2.090378284\n",
      "Epoch [111/200], Loss: 2.134461641\n",
      "0.01\n",
      "Epoch [121/200], Loss: 1.841791391\n",
      "Epoch [131/200], Loss: 2.200787783\n",
      "0.002\n",
      "Epoch [141/200], Loss: 1.914367795\n",
      "Epoch [151/200], Loss: 1.905696034\n",
      "0.0004\n",
      "Epoch [161/200], Loss: 1.819542050\n",
      "Epoch [171/200], Loss: 1.817196012\n",
      "8e-05\n",
      "Epoch [181/200], Loss: 1.865702033\n",
      "Epoch [191/200], Loss: 1.788945675\n",
      "Accuracy of the network on the test images: 29.230000 %\n",
      "lenet_Acc29.23_epoch200_lr0.05.pkl\n",
      "Epoch [1/250], Loss: 2.830701351\n",
      "Epoch [11/250], Loss: 2.805491209\n",
      "Epoch [21/250], Loss: 2.939944983\n",
      "Epoch [31/250], Loss: 2.881121397\n",
      "Epoch [41/250], Loss: 2.906331539\n",
      "Epoch [51/250], Loss: 2.839104652\n",
      "Epoch [61/250], Loss: 2.813894510\n",
      "Epoch [71/250], Loss: 2.855911493\n",
      "Epoch [81/250], Loss: 2.847507954\n",
      "Epoch [91/250], Loss: 2.931541681\n",
      "Epoch [101/250], Loss: 2.847507954\n",
      "Epoch [111/250], Loss: 2.914734840\n",
      "0.01\n",
      "Epoch [121/250], Loss: 2.897928238\n",
      "Epoch [131/250], Loss: 2.939944983\n",
      "0.002\n",
      "Epoch [141/250], Loss: 2.855911493\n",
      "Epoch [151/250], Loss: 2.847507954\n",
      "0.0004\n",
      "Epoch [161/250], Loss: 2.914734840\n",
      "Epoch [171/250], Loss: 2.822298050\n",
      "8e-05\n",
      "Epoch [181/250], Loss: 2.990365267\n",
      "Epoch [191/250], Loss: 2.855911493\n",
      "1.6e-05\n",
      "Epoch [201/250], Loss: 2.797087908\n",
      "Epoch [211/250], Loss: 2.906331539\n",
      "3.2e-06\n",
      "Epoch [221/250], Loss: 2.847507954\n",
      "Epoch [231/250], Loss: 2.864314795\n",
      "6.4e-07\n",
      "Epoch [241/250], Loss: 2.889524937\n",
      "Accuracy of the network on the test images: 6.350000 %\n",
      "mlp_Acc6.35_epoch250_lr0.05.pkl\n",
      "Epoch [1/250], Loss: 2.834371805\n",
      "Epoch [11/250], Loss: 2.837434292\n",
      "Epoch [21/250], Loss: 2.814091206\n",
      "Epoch [31/250], Loss: 2.835603237\n",
      "Epoch [41/250], Loss: 2.822084904\n",
      "Epoch [51/250], Loss: 2.801301479\n",
      "Epoch [61/250], Loss: 2.762778521\n",
      "Epoch [71/250], Loss: 2.903342485\n",
      "Epoch [81/250], Loss: 2.896460295\n",
      "Epoch [91/250], Loss: 2.846083879\n",
      "Epoch [101/250], Loss: 2.797930717\n",
      "Epoch [111/250], Loss: 2.819380522\n",
      "0.01\n",
      "Epoch [121/250], Loss: 2.782804489\n",
      "Epoch [131/250], Loss: 2.853512287\n",
      "0.002\n",
      "Epoch [141/250], Loss: 2.756525278\n",
      "Epoch [151/250], Loss: 2.817700863\n",
      "0.0004\n",
      "Epoch [161/250], Loss: 2.804598331\n",
      "Epoch [171/250], Loss: 2.758066416\n",
      "8e-05\n",
      "Epoch [181/250], Loss: 2.794496059\n",
      "Epoch [191/250], Loss: 2.792872906\n",
      "1.6e-05\n",
      "Epoch [201/250], Loss: 2.801470518\n",
      "Epoch [211/250], Loss: 2.811142206\n",
      "3.2e-06\n",
      "Epoch [221/250], Loss: 2.849834204\n",
      "Epoch [231/250], Loss: 2.803464413\n",
      "6.4e-07\n",
      "Epoch [241/250], Loss: 2.830743313\n",
      "Accuracy of the network on the test images: 10.770000 %\n",
      "lenet_Acc10.77_epoch250_lr0.05.pkl\n",
      "Epoch [1/100], Loss: 2.764361382\n",
      "Epoch [11/100], Loss: 2.723904848\n",
      "Epoch [21/100], Loss: 2.693236589\n",
      "Epoch [31/100], Loss: 2.713607073\n",
      "Epoch [41/100], Loss: 2.745632887\n",
      "Epoch [51/100], Loss: 2.674704790\n",
      "Epoch [61/100], Loss: 2.720083237\n",
      "Epoch [71/100], Loss: 2.702056170\n",
      "Epoch [81/100], Loss: 2.709683418\n",
      "Epoch [91/100], Loss: 2.725516796\n",
      "Accuracy of the network on the test images: 6.350000 %\n",
      "mlp_Acc6.35_epoch100_lr0.01.pkl\n",
      "Epoch [1/100], Loss: 2.138783455\n",
      "Epoch [11/100], Loss: 0.572162092\n",
      "Epoch [21/100], Loss: 0.207045704\n",
      "Epoch [31/100], Loss: 0.180839017\n",
      "Epoch [41/100], Loss: 0.205837443\n",
      "Epoch [51/100], Loss: 0.264116347\n",
      "Epoch [61/100], Loss: 0.106401809\n",
      "Epoch [71/100], Loss: 0.059486177\n",
      "Epoch [81/100], Loss: 0.415622413\n",
      "Epoch [91/100], Loss: 0.030273417\n",
      "Accuracy of the network on the test images: 65.960000 %\n",
      "lenet_Acc65.96_epoch100_lr0.01.pkl\n",
      "Epoch [1/150], Loss: 2.827176332\n",
      "Epoch [11/150], Loss: 2.788012743\n",
      "Epoch [21/150], Loss: 2.789648533\n",
      "Epoch [31/150], Loss: 2.803547382\n",
      "Epoch [41/150], Loss: 2.821095705\n",
      "Epoch [51/150], Loss: 2.803073883\n",
      "Epoch [61/150], Loss: 2.669412136\n",
      "Epoch [71/150], Loss: 2.751038790\n",
      "Epoch [81/150], Loss: 2.748655796\n",
      "Epoch [91/150], Loss: 2.714159250\n",
      "Epoch [101/150], Loss: 2.738995552\n",
      "Epoch [111/150], Loss: 2.806676626\n",
      "0.002\n",
      "Epoch [121/150], Loss: 2.708032370\n",
      "Epoch [131/150], Loss: 2.673824549\n",
      "0.0004\n",
      "Epoch [141/150], Loss: 2.695261478\n",
      "Accuracy of the network on the test images: 6.350000 %\n",
      "mlp_Acc6.35_epoch150_lr0.01.pkl\n",
      "Epoch [1/150], Loss: 2.263926506\n",
      "Epoch [11/150], Loss: 0.697214782\n",
      "Epoch [21/150], Loss: 0.207130149\n",
      "Epoch [31/150], Loss: 0.061917223\n",
      "Epoch [41/150], Loss: 0.140506864\n",
      "Epoch [51/150], Loss: 0.016910629\n",
      "Epoch [61/150], Loss: 0.101037130\n",
      "Epoch [71/150], Loss: 0.105312653\n",
      "Epoch [81/150], Loss: 0.258500665\n",
      "Epoch [91/150], Loss: 0.040250562\n",
      "Epoch [101/150], Loss: 0.080151603\n",
      "Epoch [111/150], Loss: 0.013034932\n",
      "0.002\n",
      "Epoch [121/150], Loss: 0.025575975\n",
      "Epoch [131/150], Loss: 0.026581172\n",
      "0.0004\n",
      "Epoch [141/150], Loss: 0.031428371\n",
      "Accuracy of the network on the test images: 64.420000 %\n",
      "lenet_Acc64.42_epoch150_lr0.01.pkl\n",
      "Epoch [1/200], Loss: 2.725348473\n",
      "Epoch [11/200], Loss: 2.794507742\n",
      "Epoch [21/200], Loss: 2.816749096\n",
      "Epoch [31/200], Loss: 2.792895555\n",
      "Epoch [41/200], Loss: 2.717705488\n",
      "Epoch [51/200], Loss: 2.787914991\n",
      "Epoch [61/200], Loss: 2.718611002\n",
      "Epoch [71/200], Loss: 2.712152481\n",
      "Epoch [81/200], Loss: 2.775698662\n",
      "Epoch [91/200], Loss: 2.691439152\n",
      "Epoch [101/200], Loss: 2.784034252\n",
      "Epoch [111/200], Loss: 2.782636166\n",
      "0.002\n",
      "Epoch [121/200], Loss: 2.754004002\n",
      "Epoch [131/200], Loss: 2.755791664\n",
      "0.0004\n",
      "Epoch [141/200], Loss: 2.714985609\n",
      "Epoch [151/200], Loss: 2.692016363\n",
      "8e-05\n",
      "Epoch [161/200], Loss: 2.688897371\n",
      "Epoch [171/200], Loss: 2.749627829\n",
      "1.6e-05\n",
      "Epoch [181/200], Loss: 2.855106831\n",
      "Epoch [191/200], Loss: 2.652248383\n",
      "Accuracy of the network on the test images: 6.350000 %\n",
      "mlp_Acc6.35_epoch200_lr0.01.pkl\n",
      "Epoch [1/200], Loss: 2.402082205\n",
      "Epoch [11/200], Loss: 0.757569134\n",
      "Epoch [21/200], Loss: 0.192165643\n",
      "Epoch [31/200], Loss: 0.053759392\n",
      "Epoch [41/200], Loss: 0.035179265\n",
      "Epoch [51/200], Loss: 0.081710167\n",
      "Epoch [61/200], Loss: 0.011592284\n",
      "Epoch [71/200], Loss: 0.027888378\n",
      "Epoch [81/200], Loss: 0.135210603\n",
      "Epoch [91/200], Loss: 0.015935473\n",
      "Epoch [101/200], Loss: 0.002601451\n",
      "Epoch [111/200], Loss: 0.157318950\n",
      "0.002\n",
      "Epoch [121/200], Loss: 0.000785243\n",
      "Epoch [131/200], Loss: 0.000038740\n",
      "0.0004\n",
      "Epoch [141/200], Loss: 0.000018921\n",
      "Epoch [151/200], Loss: 0.000024844\n",
      "8e-05\n",
      "Epoch [161/200], Loss: 0.000021077\n",
      "Epoch [171/200], Loss: 0.000041529\n",
      "1.6e-05\n",
      "Epoch [181/200], Loss: 0.000037025\n",
      "Epoch [191/200], Loss: 0.000022856\n",
      "Accuracy of the network on the test images: 68.270000 %\n",
      "lenet_Acc68.27_epoch200_lr0.01.pkl\n",
      "Epoch [1/250], Loss: 2.738153934\n",
      "Epoch [11/250], Loss: 2.738314390\n",
      "Epoch [21/250], Loss: 2.661296606\n",
      "Epoch [31/250], Loss: 2.731648207\n",
      "Epoch [41/250], Loss: 2.747137547\n",
      "Epoch [51/250], Loss: 2.728074551\n",
      "Epoch [61/250], Loss: 2.680449009\n",
      "Epoch [71/250], Loss: 2.713183165\n",
      "Epoch [81/250], Loss: 2.683865309\n",
      "Epoch [91/250], Loss: 2.625112534\n",
      "Epoch [101/250], Loss: 2.648629904\n",
      "Epoch [111/250], Loss: 2.793092966\n",
      "0.002\n",
      "Epoch [121/250], Loss: 2.696640253\n",
      "Epoch [131/250], Loss: 2.652948618\n",
      "0.0004\n",
      "Epoch [141/250], Loss: 2.657969236\n",
      "Epoch [151/250], Loss: 2.606799126\n",
      "8e-05\n",
      "Epoch [161/250], Loss: 2.669802904\n",
      "Epoch [171/250], Loss: 2.672648907\n",
      "1.6e-05\n",
      "Epoch [181/250], Loss: 2.640685797\n",
      "Epoch [191/250], Loss: 2.574524641\n",
      "3.2e-06\n",
      "Epoch [201/250], Loss: 2.574702263\n",
      "Epoch [211/250], Loss: 2.604014158\n",
      "6.4e-07\n",
      "Epoch [221/250], Loss: 2.583051205\n",
      "Epoch [231/250], Loss: 2.692917585\n",
      "1.28e-07\n",
      "Epoch [241/250], Loss: 2.637566328\n",
      "Accuracy of the network on the test images: 10.000000 %\n",
      "mlp_Acc10.0_epoch250_lr0.01.pkl\n",
      "Epoch [1/250], Loss: 2.451447248\n",
      "Epoch [11/250], Loss: 0.541801929\n",
      "Epoch [21/250], Loss: 0.142039627\n",
      "Epoch [31/250], Loss: 0.231439099\n",
      "Epoch [41/250], Loss: 0.077341519\n",
      "Epoch [51/250], Loss: 0.006084113\n",
      "Epoch [61/250], Loss: 0.066710554\n",
      "Epoch [71/250], Loss: 0.188095257\n",
      "Epoch [81/250], Loss: 0.144760936\n",
      "Epoch [91/250], Loss: 0.058144305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [101/250], Loss: 0.079744756\n",
      "Epoch [111/250], Loss: 0.047181688\n",
      "0.002\n",
      "Epoch [121/250], Loss: 0.062666774\n",
      "Epoch [131/250], Loss: 0.022972628\n",
      "0.0004\n",
      "Epoch [141/250], Loss: 0.119502030\n",
      "Epoch [151/250], Loss: 0.099486277\n",
      "8e-05\n",
      "Epoch [161/250], Loss: 0.116957657\n",
      "Epoch [171/250], Loss: 0.102685891\n",
      "1.6e-05\n",
      "Epoch [181/250], Loss: 0.190431774\n",
      "Epoch [191/250], Loss: 0.037634794\n",
      "3.2e-06\n",
      "Epoch [201/250], Loss: 0.023487682\n",
      "Epoch [211/250], Loss: 0.144931704\n",
      "6.4e-07\n",
      "Epoch [221/250], Loss: 0.134416789\n",
      "Epoch [231/250], Loss: 0.174610063\n",
      "1.28e-07\n",
      "Epoch [241/250], Loss: 0.035082988\n",
      "Accuracy of the network on the test images: 64.040000 %\n",
      "lenet_Acc64.04_epoch250_lr0.01.pkl\n",
      "Epoch [1/100], Loss: 2.812580824\n",
      "Epoch [11/100], Loss: 2.804376602\n",
      "Epoch [21/100], Loss: 2.755668879\n",
      "Epoch [31/100], Loss: 2.737233162\n",
      "Epoch [41/100], Loss: 2.770273447\n",
      "Epoch [51/100], Loss: 2.778266191\n",
      "Epoch [61/100], Loss: 2.713980436\n",
      "Epoch [71/100], Loss: 2.740723610\n",
      "Epoch [81/100], Loss: 2.748883963\n",
      "Epoch [91/100], Loss: 2.723924160\n",
      "Accuracy of the network on the test images: 8.080000 %\n",
      "mlp_Acc8.08_epoch100_lr0.005.pkl\n",
      "Epoch [1/100], Loss: 2.308208704\n",
      "Epoch [11/100], Loss: 0.955524743\n",
      "Epoch [21/100], Loss: 0.226583973\n",
      "Epoch [31/100], Loss: 0.032032300\n",
      "Epoch [41/100], Loss: 0.040548339\n",
      "Epoch [51/100], Loss: 0.003687314\n",
      "Epoch [61/100], Loss: 0.027732272\n",
      "Epoch [71/100], Loss: 0.000429041\n",
      "Epoch [81/100], Loss: 0.000215979\n",
      "Epoch [91/100], Loss: 0.000126013\n",
      "Accuracy of the network on the test images: 72.690000 %\n",
      "lenet_Acc72.69_epoch100_lr0.005.pkl\n",
      "Epoch [1/150], Loss: 2.914208651\n",
      "Epoch [11/150], Loss: 2.746062756\n",
      "Epoch [21/150], Loss: 2.731564045\n",
      "Epoch [31/150], Loss: 2.725131750\n",
      "Epoch [41/150], Loss: 2.729870081\n",
      "Epoch [51/150], Loss: 2.718323231\n",
      "Epoch [61/150], Loss: 2.729975224\n",
      "Epoch [71/150], Loss: 2.705786228\n",
      "Epoch [81/150], Loss: 2.711779594\n",
      "Epoch [91/150], Loss: 2.799235106\n",
      "Epoch [101/150], Loss: 2.714976311\n",
      "Epoch [111/150], Loss: 2.762703180\n",
      "0.001\n",
      "Epoch [121/150], Loss: 2.761111736\n",
      "Epoch [131/150], Loss: 2.754557848\n",
      "0.0002\n",
      "Epoch [141/150], Loss: 2.678745747\n",
      "Accuracy of the network on the test images: 8.850000 %\n",
      "mlp_Acc8.85_epoch150_lr0.005.pkl\n",
      "Epoch [1/150], Loss: 2.320731401\n",
      "Epoch [11/150], Loss: 0.939180255\n",
      "Epoch [21/150], Loss: 0.294949412\n",
      "Epoch [31/150], Loss: 0.167180642\n",
      "Epoch [41/150], Loss: 0.040504888\n",
      "Epoch [51/150], Loss: 0.002289139\n",
      "Epoch [61/150], Loss: 0.022545073\n",
      "Epoch [71/150], Loss: 0.015546174\n",
      "Epoch [81/150], Loss: 0.000375766\n",
      "Epoch [91/150], Loss: 0.000136183\n",
      "Epoch [101/150], Loss: 0.000072287\n",
      "Epoch [111/150], Loss: 0.000108142\n",
      "0.001\n",
      "Epoch [121/150], Loss: 0.000087746\n",
      "Epoch [131/150], Loss: 0.000092226\n",
      "0.0002\n",
      "Epoch [141/150], Loss: 0.000038155\n",
      "Accuracy of the network on the test images: 70.770000 %\n",
      "lenet_Acc70.77_epoch150_lr0.005.pkl\n",
      "Epoch [1/200], Loss: 2.834011078\n",
      "Epoch [11/200], Loss: 2.752765656\n",
      "Epoch [21/200], Loss: 2.756633520\n",
      "Epoch [31/200], Loss: 2.738143444\n",
      "Epoch [41/200], Loss: 2.734309435\n",
      "Epoch [51/200], Loss: 2.743158102\n",
      "Epoch [61/200], Loss: 2.674799204\n",
      "Epoch [71/200], Loss: 2.693675041\n",
      "Epoch [81/200], Loss: 2.732008219\n",
      "Epoch [91/200], Loss: 2.640025616\n",
      "Epoch [101/200], Loss: 2.638007879\n",
      "Epoch [111/200], Loss: 2.666296721\n",
      "0.001\n",
      "Epoch [121/200], Loss: 2.695098639\n",
      "Epoch [131/200], Loss: 2.721946239\n",
      "0.0002\n",
      "Epoch [141/200], Loss: 2.647507191\n",
      "Epoch [151/200], Loss: 2.703121901\n",
      "4e-05\n",
      "Epoch [161/200], Loss: 2.656875849\n",
      "Epoch [171/200], Loss: 2.733925104\n",
      "8e-06\n",
      "Epoch [181/200], Loss: 2.754278183\n",
      "Epoch [191/200], Loss: 2.761851072\n",
      "Accuracy of the network on the test images: 6.350000 %\n",
      "mlp_Acc6.35_epoch200_lr0.005.pkl\n",
      "Epoch [1/200], Loss: 2.248970509\n",
      "Epoch [11/200], Loss: 0.635880888\n",
      "Epoch [21/200], Loss: 0.208355278\n",
      "Epoch [31/200], Loss: 0.029484080\n",
      "Epoch [41/200], Loss: 0.071714751\n",
      "Epoch [51/200], Loss: 0.092074938\n",
      "Epoch [61/200], Loss: 0.001077508\n",
      "Epoch [71/200], Loss: 0.000158142\n",
      "Epoch [81/200], Loss: 0.000181006\n",
      "Epoch [91/200], Loss: 0.000209544\n",
      "Epoch [101/200], Loss: 0.000127544\n",
      "Epoch [111/200], Loss: 0.000139565\n",
      "0.001\n",
      "Epoch [121/200], Loss: 0.011289163\n",
      "Epoch [131/200], Loss: 0.000137537\n",
      "0.0002\n",
      "Epoch [141/200], Loss: 0.000096241\n",
      "Epoch [151/200], Loss: 0.000051226\n",
      "4e-05\n",
      "Epoch [161/200], Loss: 0.000053061\n",
      "Epoch [171/200], Loss: 0.000073930\n",
      "8e-06\n",
      "Epoch [181/200], Loss: 0.000058374\n",
      "Epoch [191/200], Loss: 0.000063391\n",
      "Accuracy of the network on the test images: 71.350000 %\n",
      "lenet_Acc71.35_epoch200_lr0.005.pkl\n",
      "Epoch [1/250], Loss: 2.742292881\n",
      "Epoch [11/250], Loss: 2.715554476\n",
      "Epoch [21/250], Loss: 2.709385872\n",
      "Epoch [31/250], Loss: 2.724734068\n",
      "Epoch [41/250], Loss: 2.701951981\n",
      "Epoch [51/250], Loss: 2.745023727\n",
      "Epoch [61/250], Loss: 2.625411034\n",
      "Epoch [71/250], Loss: 2.704155207\n",
      "Epoch [81/250], Loss: 2.761351347\n",
      "Epoch [91/250], Loss: 2.664177895\n",
      "Epoch [101/250], Loss: 2.661409855\n",
      "Epoch [111/250], Loss: 2.721732378\n",
      "0.001\n",
      "Epoch [121/250], Loss: 2.661894321\n",
      "Epoch [131/250], Loss: 2.713403225\n",
      "0.0002\n",
      "Epoch [141/250], Loss: 2.675780773\n",
      "Epoch [151/250], Loss: 2.699758530\n",
      "4e-05\n",
      "Epoch [161/250], Loss: 2.704358339\n",
      "Epoch [171/250], Loss: 2.648774385\n",
      "8e-06\n",
      "Epoch [181/250], Loss: 2.693543911\n",
      "Epoch [191/250], Loss: 2.610565186\n",
      "1.6e-06\n",
      "Epoch [201/250], Loss: 2.673642874\n",
      "Epoch [211/250], Loss: 2.703953743\n",
      "3.2e-07\n",
      "Epoch [221/250], Loss: 2.675066471\n",
      "Epoch [231/250], Loss: 2.662705660\n",
      "6.4e-08\n",
      "Epoch [241/250], Loss: 2.724590063\n",
      "Accuracy of the network on the test images: 6.350000 %\n",
      "mlp_Acc6.35_epoch250_lr0.005.pkl\n",
      "Epoch [1/250], Loss: 2.242527962\n",
      "Epoch [11/250], Loss: 0.828693449\n",
      "Epoch [21/250], Loss: 0.350665003\n",
      "Epoch [31/250], Loss: 0.128900602\n",
      "Epoch [41/250], Loss: 0.071709976\n",
      "Epoch [51/250], Loss: 0.006589437\n",
      "Epoch [61/250], Loss: 0.000371003\n",
      "Epoch [71/250], Loss: 0.000207476\n",
      "Epoch [81/250], Loss: 0.000182729\n",
      "Epoch [91/250], Loss: 0.000519592\n",
      "Epoch [101/250], Loss: 0.000361451\n",
      "Epoch [111/250], Loss: 0.000264104\n",
      "0.001\n",
      "Epoch [121/250], Loss: 0.000138852\n",
      "Epoch [131/250], Loss: 0.000103325\n",
      "0.0002\n",
      "Epoch [141/250], Loss: 0.000075693\n",
      "Epoch [151/250], Loss: 0.000068248\n",
      "4e-05\n",
      "Epoch [161/250], Loss: 0.000075957\n",
      "Epoch [171/250], Loss: 0.000023577\n",
      "8e-06\n",
      "Epoch [181/250], Loss: 0.000044759\n",
      "Epoch [191/250], Loss: 0.000056571\n",
      "1.6e-06\n",
      "Epoch [201/250], Loss: 0.000026206\n",
      "Epoch [211/250], Loss: 0.000029267\n",
      "3.2e-07\n",
      "Epoch [221/250], Loss: 0.000015010\n",
      "Epoch [231/250], Loss: 0.000019586\n",
      "6.4e-08\n",
      "Epoch [241/250], Loss: 0.000020236\n",
      "Accuracy of the network on the test images: 71.150000 %\n",
      "lenet_Acc71.15_epoch250_lr0.005.pkl\n",
      "Epoch [1/100], Loss: 2.596575975\n",
      "Epoch [11/100], Loss: 2.330971479\n",
      "Epoch [21/100], Loss: 2.250625134\n",
      "Epoch [31/100], Loss: 2.236219883\n",
      "Epoch [41/100], Loss: 2.167508125\n",
      "Epoch [51/100], Loss: 2.147454023\n",
      "Epoch [61/100], Loss: 2.126903057\n",
      "Epoch [71/100], Loss: 2.154718637\n",
      "Epoch [81/100], Loss: 2.096618176\n",
      "Epoch [91/100], Loss: 2.083508253\n",
      "Accuracy of the network on the test images: 52.310000 %\n",
      "mlp_Acc52.31_epoch100_lr0.001.pkl\n",
      "Epoch [1/100], Loss: 2.750022888\n",
      "Epoch [11/100], Loss: 1.146467328\n",
      "Epoch [21/100], Loss: 0.791964114\n",
      "Epoch [31/100], Loss: 0.751033485\n",
      "Epoch [41/100], Loss: 0.458838284\n",
      "Epoch [51/100], Loss: 0.201064080\n",
      "Epoch [61/100], Loss: 0.238321140\n",
      "Epoch [71/100], Loss: 0.107225411\n",
      "Epoch [81/100], Loss: 0.063813545\n",
      "Epoch [91/100], Loss: 0.032841343\n",
      "Accuracy of the network on the test images: 70.000000 %\n",
      "lenet_Acc70.0_epoch100_lr0.001.pkl\n",
      "Epoch [1/150], Loss: 2.615920067\n",
      "Epoch [11/150], Loss: 2.303726673\n",
      "Epoch [21/150], Loss: 2.229752541\n",
      "Epoch [31/150], Loss: 2.179008007\n",
      "Epoch [41/150], Loss: 2.147173405\n",
      "Epoch [51/150], Loss: 2.102389097\n",
      "Epoch [61/150], Loss: 2.121538401\n",
      "Epoch [71/150], Loss: 2.077639103\n",
      "Epoch [81/150], Loss: 2.090274572\n",
      "Epoch [91/150], Loss: 2.093997240\n",
      "Epoch [101/150], Loss: 2.100060701\n",
      "Epoch [111/150], Loss: 2.048310280\n",
      "0.0002\n",
      "Epoch [121/150], Loss: 2.071923494\n",
      "Epoch [131/150], Loss: 2.038139343\n",
      "4e-05\n",
      "Epoch [141/150], Loss: 2.095357895\n",
      "Accuracy of the network on the test images: 54.620000 %\n",
      "mlp_Acc54.62_epoch150_lr0.001.pkl\n",
      "Epoch [1/150], Loss: 2.661334038\n",
      "Epoch [11/150], Loss: 1.282608747\n",
      "Epoch [21/150], Loss: 0.933371842\n",
      "Epoch [31/150], Loss: 0.723230958\n",
      "Epoch [41/150], Loss: 0.640603721\n",
      "Epoch [51/150], Loss: 0.462064832\n",
      "Epoch [61/150], Loss: 0.318991005\n",
      "Epoch [71/150], Loss: 0.147339255\n",
      "Epoch [81/150], Loss: 0.249336049\n",
      "Epoch [91/150], Loss: 0.061914731\n",
      "Epoch [101/150], Loss: 0.034299690\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [111/150], Loss: 0.034896195\n",
      "0.0002\n",
      "Epoch [121/150], Loss: 0.013107740\n",
      "Epoch [131/150], Loss: 0.007562830\n",
      "4e-05\n",
      "Epoch [141/150], Loss: 0.003549383\n",
      "Accuracy of the network on the test images: 66.920000 %\n",
      "lenet_Acc66.92_epoch150_lr0.001.pkl\n",
      "Epoch [1/200], Loss: 2.608554125\n",
      "Epoch [11/200], Loss: 2.308681726\n",
      "Epoch [21/200], Loss: 2.203678370\n",
      "Epoch [31/200], Loss: 2.153811932\n",
      "Epoch [41/200], Loss: 2.176387310\n",
      "Epoch [51/200], Loss: 2.124035120\n",
      "Epoch [61/200], Loss: 2.185572147\n",
      "Epoch [71/200], Loss: 2.101729393\n",
      "Epoch [81/200], Loss: 2.113082170\n",
      "Epoch [91/200], Loss: 2.071791887\n",
      "Epoch [101/200], Loss: 2.114568233\n",
      "Epoch [111/200], Loss: 2.069540024\n",
      "0.0002\n",
      "Epoch [121/200], Loss: 2.132474184\n",
      "Epoch [131/200], Loss: 2.079413652\n",
      "4e-05\n",
      "Epoch [141/200], Loss: 2.051523447\n",
      "Epoch [151/200], Loss: 2.088352203\n",
      "8e-06\n",
      "Epoch [161/200], Loss: 2.085832119\n",
      "Epoch [171/200], Loss: 2.055813789\n",
      "1.6e-06\n",
      "Epoch [181/200], Loss: 2.048366547\n",
      "Epoch [191/200], Loss: 2.063324451\n",
      "Accuracy of the network on the test images: 49.040000 %\n",
      "mlp_Acc49.04_epoch200_lr0.001.pkl\n",
      "Epoch [1/200], Loss: 2.581454754\n",
      "Epoch [11/200], Loss: 1.320293069\n",
      "Epoch [21/200], Loss: 1.013019919\n",
      "Epoch [31/200], Loss: 0.721490383\n",
      "Epoch [41/200], Loss: 0.536386013\n",
      "Epoch [51/200], Loss: 0.394794464\n",
      "Epoch [61/200], Loss: 0.320713580\n",
      "Epoch [71/200], Loss: 0.095488854\n",
      "Epoch [81/200], Loss: 0.055100180\n",
      "Epoch [91/200], Loss: 0.037404772\n",
      "Epoch [101/200], Loss: 0.023678659\n",
      "Epoch [111/200], Loss: 0.011644724\n",
      "0.0002\n",
      "Epoch [121/200], Loss: 0.006878789\n",
      "Epoch [131/200], Loss: 0.007116390\n",
      "4e-05\n",
      "Epoch [141/200], Loss: 0.004200567\n",
      "Epoch [151/200], Loss: 0.004963771\n",
      "8e-06\n",
      "Epoch [161/200], Loss: 0.004154606\n",
      "Epoch [171/200], Loss: 0.005414298\n",
      "1.6e-06\n",
      "Epoch [181/200], Loss: 0.176832959\n",
      "Epoch [191/200], Loss: 0.007358928\n",
      "Accuracy of the network on the test images: 68.850000 %\n",
      "lenet_Acc68.85_epoch200_lr0.001.pkl\n",
      "Epoch [1/250], Loss: 2.616842508\n",
      "Epoch [11/250], Loss: 2.294337511\n",
      "Epoch [21/250], Loss: 2.244299889\n",
      "Epoch [31/250], Loss: 2.208068848\n",
      "Epoch [41/250], Loss: 2.176537514\n",
      "Epoch [51/250], Loss: 2.124982595\n",
      "Epoch [61/250], Loss: 2.130232334\n",
      "Epoch [71/250], Loss: 2.099570990\n",
      "Epoch [81/250], Loss: 2.109085083\n",
      "Epoch [91/250], Loss: 2.072891474\n",
      "Epoch [101/250], Loss: 2.060250282\n",
      "Epoch [111/250], Loss: 2.072251081\n",
      "0.0002\n",
      "Epoch [121/250], Loss: 2.088539362\n",
      "Epoch [131/250], Loss: 2.102185726\n",
      "4e-05\n",
      "Epoch [141/250], Loss: 2.091862202\n",
      "Epoch [151/250], Loss: 2.081237078\n",
      "8e-06\n",
      "Epoch [161/250], Loss: 2.033194304\n",
      "Epoch [171/250], Loss: 2.057131052\n",
      "1.6e-06\n",
      "Epoch [181/250], Loss: 2.051933289\n",
      "Epoch [191/250], Loss: 2.049621820\n",
      "3.2e-07\n",
      "Epoch [201/250], Loss: 2.093291998\n",
      "Epoch [211/250], Loss: 2.074049473\n",
      "6.4e-08\n",
      "Epoch [221/250], Loss: 2.011293173\n",
      "Epoch [231/250], Loss: 2.069978237\n",
      "1.28e-08\n",
      "Epoch [241/250], Loss: 2.038736105\n",
      "Accuracy of the network on the test images: 54.420000 %\n",
      "mlp_Acc54.42_epoch250_lr0.001.pkl\n",
      "Epoch [1/250], Loss: 2.626604795\n",
      "Epoch [11/250], Loss: 1.094646573\n",
      "Epoch [21/250], Loss: 0.792300105\n",
      "Epoch [31/250], Loss: 0.808508694\n",
      "Epoch [41/250], Loss: 0.404896677\n",
      "Epoch [51/250], Loss: 0.273637533\n",
      "Epoch [61/250], Loss: 0.165728524\n",
      "Epoch [71/250], Loss: 0.110305883\n",
      "Epoch [81/250], Loss: 0.093393326\n",
      "Epoch [91/250], Loss: 0.026609501\n",
      "Epoch [101/250], Loss: 0.010396653\n",
      "Epoch [111/250], Loss: 0.007860648\n",
      "0.0002\n",
      "Epoch [121/250], Loss: 0.005667117\n",
      "Epoch [131/250], Loss: 0.004449604\n",
      "4e-05\n",
      "Epoch [141/250], Loss: 0.003514514\n",
      "Epoch [151/250], Loss: 0.276112378\n",
      "8e-06\n",
      "Epoch [161/250], Loss: 0.012311358\n",
      "Epoch [171/250], Loss: 0.002270282\n",
      "1.6e-06\n",
      "Epoch [181/250], Loss: 0.001312400\n",
      "Epoch [191/250], Loss: 0.004349284\n",
      "3.2e-07\n",
      "Epoch [201/250], Loss: 0.001366808\n",
      "Epoch [211/250], Loss: 0.001644828\n",
      "6.4e-08\n",
      "Epoch [221/250], Loss: 0.000750466\n",
      "Epoch [231/250], Loss: 0.000727862\n",
      "1.28e-08\n",
      "Epoch [241/250], Loss: 0.001393583\n",
      "Accuracy of the network on the test images: 68.850000 %\n",
      "lenet_Acc68.85_epoch250_lr0.001.pkl\n",
      "Epoch [1/100], Loss: 2.627100229\n",
      "Epoch [11/100], Loss: 2.317943811\n",
      "Epoch [21/100], Loss: 2.244678259\n",
      "Epoch [31/100], Loss: 2.176024914\n",
      "Epoch [41/100], Loss: 2.144840479\n",
      "Epoch [51/100], Loss: 2.085461378\n",
      "Epoch [61/100], Loss: 2.071093798\n",
      "Epoch [71/100], Loss: 2.057297230\n",
      "Epoch [81/100], Loss: 2.065680504\n",
      "Epoch [91/100], Loss: 2.061143637\n",
      "Accuracy of the network on the test images: 52.120000 %\n",
      "mlp_Acc52.12_epoch100_lr0.0005.pkl\n",
      "Epoch [1/100], Loss: 2.797327042\n",
      "Epoch [11/100], Loss: 1.585663915\n",
      "Epoch [21/100], Loss: 1.189375877\n",
      "Epoch [31/100], Loss: 0.932174444\n",
      "Epoch [41/100], Loss: 0.815752864\n",
      "Epoch [51/100], Loss: 0.721537411\n",
      "Epoch [61/100], Loss: 0.595186830\n",
      "Epoch [71/100], Loss: 0.517143607\n",
      "Epoch [81/100], Loss: 0.531642616\n",
      "Epoch [91/100], Loss: 0.378671378\n",
      "Accuracy of the network on the test images: 68.460000 %\n",
      "lenet_Acc68.46_epoch100_lr0.0005.pkl\n",
      "Epoch [1/150], Loss: 2.608039141\n",
      "Epoch [11/150], Loss: 2.297524214\n",
      "Epoch [21/150], Loss: 2.191165447\n",
      "Epoch [31/150], Loss: 2.185148001\n",
      "Epoch [41/150], Loss: 2.125313044\n",
      "Epoch [51/150], Loss: 2.132873297\n",
      "Epoch [61/150], Loss: 2.090414524\n",
      "Epoch [71/150], Loss: 2.043248415\n",
      "Epoch [81/150], Loss: 2.033987045\n",
      "Epoch [91/150], Loss: 2.024562836\n",
      "Epoch [101/150], Loss: 2.018147230\n",
      "Epoch [111/150], Loss: 2.012661457\n",
      "0.0001\n",
      "Epoch [121/150], Loss: 2.016700745\n",
      "Epoch [131/150], Loss: 2.035500288\n",
      "2e-05\n",
      "Epoch [141/150], Loss: 2.021677256\n",
      "Accuracy of the network on the test images: 51.730000 %\n",
      "mlp_Acc51.73_epoch150_lr0.0005.pkl\n",
      "Epoch [1/150], Loss: 2.803704262\n",
      "Epoch [11/150], Loss: 1.450650096\n",
      "Epoch [21/150], Loss: 1.097844124\n",
      "Epoch [31/150], Loss: 0.880831182\n",
      "Epoch [41/150], Loss: 0.704079747\n",
      "Epoch [51/150], Loss: 0.612410367\n",
      "Epoch [61/150], Loss: 0.564743340\n",
      "Epoch [71/150], Loss: 0.472525537\n",
      "Epoch [81/150], Loss: 0.359255046\n",
      "Epoch [91/150], Loss: 0.270327955\n",
      "Epoch [101/150], Loss: 0.269441754\n",
      "Epoch [111/150], Loss: 0.185662121\n",
      "0.0001\n",
      "Epoch [121/150], Loss: 0.129249424\n",
      "Epoch [131/150], Loss: 0.125183627\n",
      "2e-05\n",
      "Epoch [141/150], Loss: 0.099759988\n",
      "Accuracy of the network on the test images: 64.040000 %\n",
      "lenet_Acc64.04_epoch150_lr0.0005.pkl\n",
      "Epoch [1/200], Loss: 2.609513283\n",
      "Epoch [11/200], Loss: 2.318938494\n",
      "Epoch [21/200], Loss: 2.189160824\n",
      "Epoch [31/200], Loss: 2.142547131\n",
      "Epoch [41/200], Loss: 2.105123043\n",
      "Epoch [51/200], Loss: 2.080416203\n",
      "Epoch [61/200], Loss: 2.058618784\n",
      "Epoch [71/200], Loss: 2.062255144\n",
      "Epoch [81/200], Loss: 2.028981209\n",
      "Epoch [91/200], Loss: 2.027266026\n",
      "Epoch [101/200], Loss: 2.063522100\n",
      "Epoch [111/200], Loss: 2.016269922\n",
      "0.0001\n",
      "Epoch [121/200], Loss: 2.035871506\n",
      "Epoch [131/200], Loss: 2.000481129\n",
      "2e-05\n",
      "Epoch [141/200], Loss: 2.006658554\n",
      "Epoch [151/200], Loss: 1.992691159\n",
      "4e-06\n",
      "Epoch [161/200], Loss: 2.022380352\n",
      "Epoch [171/200], Loss: 2.021113634\n",
      "8e-07\n",
      "Epoch [181/200], Loss: 2.015877724\n",
      "Epoch [191/200], Loss: 2.006335974\n",
      "Accuracy of the network on the test images: 54.810000 %\n",
      "mlp_Acc54.81_epoch200_lr0.0005.pkl\n",
      "Epoch [1/200], Loss: 2.758350849\n",
      "Epoch [11/200], Loss: 1.355536819\n",
      "Epoch [21/200], Loss: 1.045828581\n",
      "Epoch [31/200], Loss: 0.722047567\n",
      "Epoch [41/200], Loss: 0.739026010\n",
      "Epoch [51/200], Loss: 0.594224453\n",
      "Epoch [61/200], Loss: 0.537906587\n",
      "Epoch [71/200], Loss: 0.420192659\n",
      "Epoch [81/200], Loss: 0.441610396\n",
      "Epoch [91/200], Loss: 0.322477877\n",
      "Epoch [101/200], Loss: 0.379779905\n",
      "Epoch [111/200], Loss: 0.191015467\n",
      "0.0001\n",
      "Epoch [121/200], Loss: 0.143556073\n",
      "Epoch [131/200], Loss: 0.129459664\n",
      "2e-05\n",
      "Epoch [141/200], Loss: 0.084112249\n",
      "Epoch [151/200], Loss: 0.047174364\n",
      "4e-06\n",
      "Epoch [161/200], Loss: 0.034104280\n",
      "Epoch [171/200], Loss: 0.047076374\n",
      "8e-07\n",
      "Epoch [181/200], Loss: 0.028238084\n",
      "Epoch [191/200], Loss: 0.022472069\n",
      "Accuracy of the network on the test images: 66.730000 %\n",
      "lenet_Acc66.73_epoch200_lr0.0005.pkl\n",
      "Epoch [1/250], Loss: 2.584750175\n",
      "Epoch [11/250], Loss: 2.284243107\n",
      "Epoch [21/250], Loss: 2.223717690\n",
      "Epoch [31/250], Loss: 2.166092873\n",
      "Epoch [41/250], Loss: 2.126570225\n",
      "Epoch [51/250], Loss: 2.099187136\n",
      "Epoch [61/250], Loss: 2.118560553\n",
      "Epoch [71/250], Loss: 2.073020220\n",
      "Epoch [81/250], Loss: 2.098809481\n",
      "Epoch [91/250], Loss: 2.068759918\n",
      "Epoch [101/250], Loss: 2.071942568\n",
      "Epoch [111/250], Loss: 2.058067322\n",
      "0.0001\n",
      "Epoch [121/250], Loss: 2.067055702\n",
      "Epoch [131/250], Loss: 2.046591282\n",
      "2e-05\n",
      "Epoch [141/250], Loss: 2.027562141\n",
      "Epoch [151/250], Loss: 2.018813610\n",
      "4e-06\n",
      "Epoch [161/250], Loss: 2.055727243\n",
      "Epoch [171/250], Loss: 2.060997248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8e-07\n",
      "Epoch [181/250], Loss: 2.056764126\n",
      "Epoch [191/250], Loss: 2.030493259\n",
      "1.6e-07\n",
      "Epoch [201/250], Loss: 2.040055513\n",
      "Epoch [211/250], Loss: 2.056095362\n",
      "3.2e-08\n",
      "Epoch [221/250], Loss: 2.013525486\n",
      "Epoch [231/250], Loss: 2.013065338\n",
      "6.4e-09\n",
      "Epoch [241/250], Loss: 2.016839266\n",
      "Accuracy of the network on the test images: 50.190000 %\n",
      "mlp_Acc50.19_epoch250_lr0.0005.pkl\n",
      "Epoch [1/250], Loss: 2.771508455\n",
      "Epoch [11/250], Loss: 1.357573152\n",
      "Epoch [21/250], Loss: 1.106738806\n",
      "Epoch [31/250], Loss: 0.898245931\n",
      "Epoch [41/250], Loss: 0.857666373\n",
      "Epoch [51/250], Loss: 0.597440839\n",
      "Epoch [61/250], Loss: 0.547264040\n",
      "Epoch [71/250], Loss: 0.348891765\n",
      "Epoch [81/250], Loss: 0.276636839\n",
      "Epoch [91/250], Loss: 0.180542409\n",
      "Epoch [101/250], Loss: 0.117749304\n",
      "Epoch [111/250], Loss: 0.087481923\n",
      "0.0001\n",
      "Epoch [121/250], Loss: 0.066063389\n",
      "Epoch [131/250], Loss: 0.056193393\n",
      "2e-05\n",
      "Epoch [141/250], Loss: 0.027760522\n",
      "Epoch [151/250], Loss: 0.019557392\n",
      "4e-06\n",
      "Epoch [161/250], Loss: 0.014029599\n",
      "Epoch [171/250], Loss: 0.008256295\n",
      "8e-07\n",
      "Epoch [181/250], Loss: 0.011923854\n",
      "Epoch [191/250], Loss: 0.007091330\n",
      "1.6e-07\n",
      "Epoch [201/250], Loss: 0.009903587\n",
      "Epoch [211/250], Loss: 0.039037690\n",
      "3.2e-08\n",
      "Epoch [221/250], Loss: 0.038985908\n",
      "Epoch [231/250], Loss: 0.004045374\n",
      "6.4e-09\n",
      "Epoch [241/250], Loss: 0.004574223\n",
      "Accuracy of the network on the test images: 67.120000 %\n",
      "lenet_Acc67.12_epoch250_lr0.0005.pkl\n",
      "Epoch [1/100], Loss: 2.641489983\n",
      "Epoch [11/100], Loss: 2.402266502\n",
      "Epoch [21/100], Loss: 2.293406487\n",
      "Epoch [31/100], Loss: 2.195399523\n",
      "Epoch [41/100], Loss: 2.163373232\n",
      "Epoch [51/100], Loss: 2.096745491\n",
      "Epoch [61/100], Loss: 2.078448772\n",
      "Epoch [71/100], Loss: 2.074841261\n",
      "Epoch [81/100], Loss: 2.056537390\n",
      "Epoch [91/100], Loss: 2.052364349\n",
      "Accuracy of the network on the test images: 54.420000 %\n",
      "mlp_Acc54.42_epoch100_lr0.0001.pkl\n",
      "Epoch [1/100], Loss: 2.892352343\n",
      "Epoch [11/100], Loss: 2.122482538\n",
      "Epoch [21/100], Loss: 1.832783937\n",
      "Epoch [31/100], Loss: 1.472082973\n",
      "Epoch [41/100], Loss: 1.495466113\n",
      "Epoch [51/100], Loss: 1.313505650\n",
      "Epoch [61/100], Loss: 1.321245432\n",
      "Epoch [71/100], Loss: 1.192376733\n",
      "Epoch [81/100], Loss: 1.116164207\n",
      "Epoch [91/100], Loss: 1.057032585\n",
      "Accuracy of the network on the test images: 58.850000 %\n",
      "lenet_Acc58.85_epoch100_lr0.0001.pkl\n",
      "Epoch [1/150], Loss: 2.663022995\n",
      "Epoch [11/150], Loss: 2.410273075\n",
      "Epoch [21/150], Loss: 2.301674366\n",
      "Epoch [31/150], Loss: 2.216454029\n",
      "Epoch [41/150], Loss: 2.139539480\n",
      "Epoch [51/150], Loss: 2.122416496\n",
      "Epoch [61/150], Loss: 2.122861624\n",
      "Epoch [71/150], Loss: 2.072699547\n",
      "Epoch [81/150], Loss: 2.076845407\n",
      "Epoch [91/150], Loss: 2.036191463\n",
      "Epoch [101/150], Loss: 2.036185265\n",
      "Epoch [111/150], Loss: 2.024145603\n",
      "2e-05\n",
      "Epoch [121/150], Loss: 2.012177706\n",
      "Epoch [131/150], Loss: 2.022753716\n",
      "4e-06\n",
      "Epoch [141/150], Loss: 2.010863304\n",
      "Accuracy of the network on the test images: 53.850000 %\n",
      "mlp_Acc53.85_epoch150_lr0.0001.pkl\n",
      "Epoch [1/150], Loss: 2.879885435\n",
      "Epoch [11/150], Loss: 2.152093172\n",
      "Epoch [21/150], Loss: 1.709040165\n",
      "Epoch [31/150], Loss: 1.585394740\n",
      "Epoch [41/150], Loss: 1.460467219\n",
      "Epoch [51/150], Loss: 1.373413563\n",
      "Epoch [61/150], Loss: 1.455482006\n",
      "Epoch [71/150], Loss: 1.205701709\n",
      "Epoch [81/150], Loss: 1.217397571\n",
      "Epoch [91/150], Loss: 1.168431640\n",
      "Epoch [101/150], Loss: 1.282047987\n",
      "Epoch [111/150], Loss: 1.118869781\n",
      "2e-05\n",
      "Epoch [121/150], Loss: 0.996347368\n",
      "Epoch [131/150], Loss: 1.083872676\n",
      "4e-06\n",
      "Epoch [141/150], Loss: 1.021748543\n",
      "Accuracy of the network on the test images: 59.620000 %\n",
      "lenet_Acc59.62_epoch150_lr0.0001.pkl\n",
      "Epoch [1/200], Loss: 2.654890776\n",
      "Epoch [11/200], Loss: 2.392300606\n",
      "Epoch [21/200], Loss: 2.291011333\n",
      "Epoch [31/200], Loss: 2.188182116\n",
      "Epoch [41/200], Loss: 2.155191660\n",
      "Epoch [51/200], Loss: 2.141538143\n",
      "Epoch [61/200], Loss: 2.083850145\n",
      "Epoch [71/200], Loss: 2.068867207\n",
      "Epoch [81/200], Loss: 2.072235107\n",
      "Epoch [91/200], Loss: 2.062634230\n",
      "Epoch [101/200], Loss: 2.044679165\n",
      "Epoch [111/200], Loss: 2.012115479\n",
      "2e-05\n",
      "Epoch [121/200], Loss: 2.034785986\n",
      "Epoch [131/200], Loss: 2.001534700\n",
      "4e-06\n",
      "Epoch [141/200], Loss: 2.002190828\n",
      "Epoch [151/200], Loss: 2.025759459\n",
      "8e-07\n",
      "Epoch [161/200], Loss: 2.001439095\n",
      "Epoch [171/200], Loss: 2.003709078\n",
      "1.6e-07\n",
      "Epoch [181/200], Loss: 2.006811857\n",
      "Epoch [191/200], Loss: 2.009516239\n",
      "Accuracy of the network on the test images: 55.960000 %\n",
      "mlp_Acc55.96_epoch200_lr0.0001.pkl\n",
      "Epoch [1/200], Loss: 2.904834747\n",
      "Epoch [11/200], Loss: 2.349910498\n",
      "Epoch [21/200], Loss: 1.796054721\n",
      "Epoch [31/200], Loss: 1.659616828\n",
      "Epoch [41/200], Loss: 1.507956266\n",
      "Epoch [51/200], Loss: 1.282813668\n",
      "Epoch [61/200], Loss: 1.135060072\n",
      "Epoch [71/200], Loss: 1.255975962\n",
      "Epoch [81/200], Loss: 1.216699481\n",
      "Epoch [91/200], Loss: 1.142847061\n",
      "Epoch [101/200], Loss: 1.108461499\n",
      "Epoch [111/200], Loss: 1.133238792\n",
      "2e-05\n",
      "Epoch [121/200], Loss: 0.894487858\n",
      "Epoch [131/200], Loss: 1.071890354\n",
      "4e-06\n",
      "Epoch [141/200], Loss: 0.887992084\n",
      "Epoch [151/200], Loss: 0.948430896\n",
      "8e-07\n",
      "Epoch [161/200], Loss: 0.796703935\n",
      "Epoch [171/200], Loss: 0.882568121\n",
      "1.6e-07\n",
      "Epoch [181/200], Loss: 0.707515061\n",
      "Epoch [191/200], Loss: 0.966842532\n",
      "Accuracy of the network on the test images: 61.540000 %\n",
      "lenet_Acc61.54_epoch200_lr0.0001.pkl\n",
      "Epoch [1/250], Loss: 2.668105602\n",
      "Epoch [11/250], Loss: 2.409645319\n",
      "Epoch [21/250], Loss: 2.270446777\n",
      "Epoch [31/250], Loss: 2.230517387\n",
      "Epoch [41/250], Loss: 2.157462835\n",
      "Epoch [51/250], Loss: 2.105498075\n",
      "Epoch [61/250], Loss: 2.082721949\n",
      "Epoch [71/250], Loss: 2.086275578\n",
      "Epoch [81/250], Loss: 2.044664860\n",
      "Epoch [91/250], Loss: 2.035580158\n",
      "Epoch [101/250], Loss: 2.031826019\n",
      "Epoch [111/250], Loss: 2.056669950\n",
      "2e-05\n",
      "Epoch [121/250], Loss: 2.015450716\n",
      "Epoch [131/250], Loss: 2.004153013\n",
      "4e-06\n",
      "Epoch [141/250], Loss: 2.009417772\n",
      "Epoch [151/250], Loss: 2.026188850\n",
      "8e-07\n",
      "Epoch [161/250], Loss: 2.007507801\n",
      "Epoch [171/250], Loss: 2.010866404\n",
      "1.6e-07\n",
      "Epoch [181/250], Loss: 2.010516405\n",
      "Epoch [191/250], Loss: 2.014476776\n",
      "3.2e-08\n",
      "Epoch [201/250], Loss: 1.998399258\n",
      "Epoch [211/250], Loss: 2.016594887\n",
      "6.4e-09\n",
      "Epoch [221/250], Loss: 2.000642300\n",
      "Epoch [231/250], Loss: 2.007537365\n",
      "1.28e-09\n",
      "Epoch [241/250], Loss: 2.161050320\n",
      "Accuracy of the network on the test images: 56.920000 %\n",
      "mlp_Acc56.92_epoch250_lr0.0001.pkl\n",
      "Epoch [1/250], Loss: 2.874244213\n",
      "Epoch [11/250], Loss: 2.078867197\n",
      "Epoch [21/250], Loss: 1.605490088\n",
      "Epoch [31/250], Loss: 1.644540906\n",
      "Epoch [41/250], Loss: 1.382652998\n",
      "Epoch [51/250], Loss: 1.375239611\n",
      "Epoch [61/250], Loss: 1.196087003\n",
      "Epoch [71/250], Loss: 1.263399959\n",
      "Epoch [81/250], Loss: 1.017121196\n",
      "Epoch [91/250], Loss: 0.992360651\n",
      "Epoch [101/250], Loss: 0.911909103\n",
      "Epoch [111/250], Loss: 0.869650900\n",
      "2e-05\n",
      "Epoch [121/250], Loss: 0.873022377\n",
      "Epoch [131/250], Loss: 0.820323825\n",
      "4e-06\n",
      "Epoch [141/250], Loss: 0.752625287\n",
      "Epoch [151/250], Loss: 0.784788907\n",
      "8e-07\n",
      "Epoch [161/250], Loss: 0.746044457\n",
      "Epoch [171/250], Loss: 0.761791646\n",
      "1.6e-07\n",
      "Epoch [181/250], Loss: 0.800624073\n",
      "Epoch [191/250], Loss: 0.638608813\n",
      "3.2e-08\n",
      "Epoch [201/250], Loss: 0.684480429\n",
      "Epoch [211/250], Loss: 0.579811037\n",
      "6.4e-09\n",
      "Epoch [221/250], Loss: 0.748695552\n",
      "Epoch [231/250], Loss: 0.717255473\n",
      "1.28e-09\n",
      "Epoch [241/250], Loss: 0.671886146\n",
      "Accuracy of the network on the test images: 64.420000 %\n",
      "lenet_Acc64.42_epoch250_lr0.0001.pkl\n"
     ]
    }
   ],
   "source": [
    "for learning_rate in [0.1,0.05,0.01,0.005,0.001,0.0005,0.0001]:\n",
    "    initial_learning_rate = learning_rate\n",
    "    for num_epochs in [100,150,200,250]:\n",
    "#====================================================================================================\n",
    "# MLP\n",
    "#====================================================================================================\n",
    "        mlp = MLP()\n",
    "        mlp.cuda()\n",
    "\n",
    "\n",
    "        batch_size = 100\n",
    "        learning_rate=initial_learning_rate\n",
    "        img_dir = \"/home/junhyun/Junhyun/train/\"\n",
    "\n",
    "        # img_data = dset.ImageFolder(img_dir)\n",
    "        img_data_mlp = dset.ImageFolder(img_dir, transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean = [0.778163803690477, 0.62366406713856704, 0.62748488269742386],std = [0.18654390350275066, 0.25577185166630317, 0.22957029180170951])\n",
    "        ]))\n",
    "\n",
    "        img_batch_mlp = data.DataLoader(img_data_mlp, batch_size=batch_size,\n",
    "                                    shuffle=True, num_workers=2)\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(mlp.parameters(), lr=learning_rate)\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            i=0\n",
    "            if (epoch > 100)and(epoch%20==0):\n",
    "                learning_rate= learning_rate*0.2\n",
    "                print(learning_rate)\n",
    "\n",
    "            for img,label in img_batch_mlp:\n",
    "                images = Variable(img).cuda()\n",
    "                labels = Variable(label).cuda()\n",
    "\n",
    "                # Forward + Backward + Optimize\n",
    "                optimizer.zero_grad()\n",
    "                outputs = mlp(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                i+=1\n",
    "                if i%100 ==0:\n",
    "                    print('step : %d'%i)\n",
    "\n",
    "            if epoch%10 ==0:\n",
    "                print ('Epoch [%d/%d], Loss: %.9f'%(epoch+1, num_epochs, loss.data[0]))\n",
    "\n",
    "\n",
    "        img_dir = \"/home/junhyun/Junhyun/val\"\n",
    "\n",
    "        test_dataset = dset.ImageFolder(img_dir, transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean = [0.778163803690477, 0.62366406713856704, 0.62748488269742386],std = [0.18654390350275066, 0.25577185166630317, 0.22957029180170951])\n",
    "        ]))\n",
    "\n",
    "\n",
    "        test_batch = data.DataLoader(test_dataset, batch_size=100,\n",
    "                                    shuffle=True, num_workers=2)\n",
    "\n",
    "        # Test the Model\\\n",
    "        mlp.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for img,labels in test_batch:\n",
    "            images = Variable(img).cuda()\n",
    "            outputs = mlp(images)\n",
    "            _, predicted = torch.max(outputs.data,1)\n",
    "            total+= labels.size(0)\n",
    "            correct += (predicted.cpu() == labels).sum()\n",
    "\n",
    "        Acc = round(100.0 * float(correct) / float(total),2)\n",
    "        print('Accuracy of the network on the test images: %f %%' % (Acc))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        save_name = 'mlp_Acc' + str(Acc)[:5] + '_epoch' + str(num_epochs) + '_lr' + str(initial_learning_rate) + '.pkl'\n",
    "        print(save_name)\n",
    "        torch.save(mlp.state_dict(), save_name)\n",
    "\n",
    "\n",
    "\n",
    "#====================================================================================================\n",
    "# MLP\n",
    "#====================================================================================================\n",
    "\n",
    "\n",
    "        lenet = LeNet()\n",
    "        lenet.cuda()\n",
    "\n",
    "\n",
    "        batch_size = 100\n",
    "        learning_rate=initial_learning_rate\n",
    "\n",
    "        img_dir = \"/home/junhyun/Junhyun/train/\"\n",
    "\n",
    "        img_data_lenet = dset.ImageFolder(img_dir, transforms.Compose([\n",
    "        #     transforms.ToPILImage(),\n",
    "            transforms.Scale(32,interpolation=Image.BICUBIC),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean = [0.778163803690477, 0.62366406713856704, 0.62748488269742386],std = [0.18654390350275066, 0.25577185166630317, 0.22957029180170951])\n",
    "        ]))\n",
    "\n",
    "        img_batch_lenet = data.DataLoader(img_data_lenet, batch_size=batch_size,\n",
    "                                    shuffle=True, num_workers=2)\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(lenet.parameters(), lr=learning_rate)\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            i=0\n",
    "            if (epoch > 100)and(epoch%20==0):\n",
    "                learning_rate= learning_rate*0.2\n",
    "                print(learning_rate)\n",
    "            for img,label in img_batch_lenet:\n",
    "                images = Variable(img).cuda()\n",
    "                labels = Variable(label).cuda()\n",
    "\n",
    "                # Forward + Backward + Optimize\n",
    "                optimizer.zero_grad()\n",
    "                outputs = lenet(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                i+=1\n",
    "                if i%100 ==0:\n",
    "                    print('step : %d'%i)\n",
    "\n",
    "            if epoch%10 ==0:\n",
    "                print ('Epoch [%d/%d], Loss: %.9f'%(epoch+1, num_epochs, loss.data[0]))\n",
    "\n",
    "\n",
    "        img_dir = \"/home/junhyun/Junhyun/val\"\n",
    "\n",
    "        test_dataset = dset.ImageFolder(img_dir, transforms.Compose([\n",
    "        #     transforms.ToPILImage(),\n",
    "            transforms.Scale(32,interpolation=Image.BICUBIC),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean = [0.778163803690477, 0.62366406713856704, 0.62748488269742386],std = [0.18654390350275066, 0.25577185166630317, 0.22957029180170951])\n",
    "        ]))\n",
    "\n",
    "        test_batch = data.DataLoader(test_dataset, batch_size=batch_size,\n",
    "                                    shuffle=False, num_workers=2)\n",
    "\n",
    "        # Test the Model\n",
    "        lenet.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for img,labels in test_batch:\n",
    "            images = Variable(img).cuda()\n",
    "            outputs = lenet(images)\n",
    "            _, predicted = torch.max(outputs.data,1)\n",
    "            total+= labels.size(0)\n",
    "            correct += (predicted.cpu() == labels).sum()\n",
    "\n",
    "\n",
    "        Acc = round(100.0 * float(correct) / float(total),2)\n",
    "        print('Accuracy of the network on the test images: %f %%' % (Acc))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        save_name = 'lenet_Acc' + str(Acc)[:5] + '_epoch' + str(num_epochs) + '_lr' + str(initial_learning_rate) +  '.pkl'\n",
    "        print(save_name)\n",
    "\n",
    "        torch.save(lenet.state_dict(), save_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
